{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Shipping manifest matching table\n",
    "\n",
    "\n",
    "Several MTA: BioRep, IU, TA    \n",
    "\n",
    "Create the table of all barcodes per persion. \n",
    "\n",
    "The table is compared with the summary table created previously\n",
    "\n",
    "Table is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lscratch/21965786/MTA exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from functools import partial\n",
    "from os import chdir\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "tmp = '/lscratch/' + os.environ['SLURM_JOB_ID'] + '/MTA'\n",
    "if os.path.exists(tmp):\n",
    "    print(tmp, 'exists')\n",
    "else:\n",
    "    os.mkdir(tmp)\n",
    "    print('Make', tmp)\n",
    "\n",
    "chdir(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /data/LNG/iwakih2/dataset/PPMI/WGS/Shipping/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BioRepF1 = pd.read_excel('BioRep Full List PPMI 01252016.xlsx', sheet_name='To Be Aliquoted', dtype={'Specimen Bar Code':object})\n",
    "BioRepF1.index = BioRepF1['Last Name']\n",
    "BioRepF1 = BioRepF1[['Specimen Bar Code']]\n",
    "\n",
    "BioRepF2 = pd.read_excel('BioRep Full List PPMI 01252016.xlsx', sheet_name='To Pull for Shipping', dtype={'Specimen Bar Code':object})\n",
    "BioRepF2.index = BioRepF2['Last Name']\n",
    "BioRepF2= BioRepF2[['Specimen Bar Code']]\n",
    "\n",
    "BioRepM1 = pd.read_excel('BioRep Manifest Singleton PPMI DNA.xlsx', sheet_name='Sheet1', dtype={'Specimen bar code':object})\n",
    "BioRepM1.index = BioRepM1['PPMI ID']\n",
    "BioRepM1= BioRepM1[['Specimen bar code']]\n",
    "\n",
    "BioRep=BioRepF1.join(BioRepF2, how='outer', lsuffix='BioRepF1', rsuffix='BioRepF2').join(BioRepM1, how='outer', rsuffix='BioRepM')\n",
    "BioRep.to_csv(\"BioRep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IUF1 = pd.read_excel('IU Full List PPMI 01252016.xlsx', sheet_name='To Be Aliquoted', dtype={'Specimen Bar Code':object})\n",
    "IUF1.index = IUF1['Last Name']\n",
    "IUF1 = IUF1[['Specimen Bar Code']]\n",
    "\n",
    "IUF2 = pd.read_excel('IU Full List PPMI 01252016.xlsx', sheet_name='To Pull for Shipping', dtype={'Specimen Bar Code':object})\n",
    "IUF2.index = IUF2['Last Name']\n",
    "IUF2= IUF2[['Specimen Bar Code']]\n",
    "\n",
    "IUM1 = pd.read_excel('IU Manifest Singleton PPMI DNA.XLSX', sheet_name='Sheet1', dtype={'Specimen Bar Code':object})\n",
    "IUM1.index = IUM1['PPMI ID']\n",
    "IUM1= IUM1[['Specimen Bar Code']]\n",
    "\n",
    "IU=IUF1.join(IUF2, how='outer', lsuffix='IUF1', rsuffix='IUF2').join(IUM1, how = 'outer', rsuffix='IUM')\n",
    "IU.to_csv(\"IU.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAP1 = pd.read_excel('TA PPMI Singleton Feb 2017.xlsx', sheet_name='Sheet1', dtype={'Specimen Bar Code':object})\n",
    "TAP1.index = TAP1['Last Name']\n",
    "TAP1 = TAP1[['Specimen Bar Code']]\n",
    "\n",
    "TAM1 = pd.read_excel('TA Manifest Singleton PPMI DNA.xlsx', sheet_name='Sheet1', dtype={'Specimen bar code':object})\n",
    "TAM1.index = TAM1['PPMI ID']\n",
    "TAM1= TAM1[['Specimen bar code']]\n",
    "\n",
    "TA = TAP1.join(TAM1, how = 'outer', lsuffix='TA1', rsuffix='TAM')\n",
    "TA.to_csv(\"TA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All = BioRep.join(IU, how = 'outer', lsuffix='BioRep', rsuffix='IU').join(TA, how = 'outer',lsuffix=\"_\", rsuffix='TA')\n",
    "All2 = All.iloc[All.index>0, :]\n",
    "All2.to_csv(\"BioRep_IU_TA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barcode1    1599\n",
       "barcode2     221\n",
       "barcode3      61\n",
       "barcode4       0\n",
       "barcode5       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of barcodes per person\n",
    "ref = pd.read_csv(\"BioRep_IU_TA.csv\", header=0, names=['v1', \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\"], dtype=object)\n",
    "uniqIDs = ref.index[ref.index.duplicated()==False]\n",
    "barcodes=[]\n",
    "for ID in uniqIDs:\n",
    "    t1 = ref[ref.index==ID]\n",
    "    t2 =[i for i in t1.values.reshape(-1) if not pd.isnull(i)]\n",
    "    uniq_bar = list(set(t2))\n",
    "    fill = 5 - len(uniq_bar) # 5 slots are enough for one person's barcodes\n",
    "    uniq_bar.extend([np.nan]*fill)\n",
    "    barcodes.append(uniq_bar) \n",
    "barcodeT = pd.DataFrame(data = barcodes,\n",
    "                  index = uniqIDs.astype('float32').astype('int').astype('object'),\n",
    "                  columns = ['barcode1', 'barcode2', 'barcode3', 'barcode4', 'barcode5'])\n",
    "barcodeT.notna().apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID4 and ID5 because they are unused slots.\n",
    "barcodeT = barcodeT.drop(['barcode4', 'barcode5'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read another FILE which was created previously (The summarized one)\n",
    "FILE=pd.read_excel(\"Barcode_PPMI_NIA_AMPPD_ShipandSeq_Summary060118FINALC.xlsx\", sheet_name='Annotated PPMI Subj List',  dtype=object)\n",
    "FILE.index=FILE['MJFF Record']\n",
    "Match = FILE.join(barcodeT, how='outer')\n",
    "Match['PATNO'] = Match.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matching barcode1-3 to ones in the summarized one\n",
    "def giveStatus1(x):\n",
    "    v = x[['barcode1', 'barcode2', 'barcode3']].isin([x['1st Shipment Barcodes']]) # if 1st Shipment Barcode is in Manifest\n",
    "    if pd.isnull(x['1st Shipment Barcodes']):\n",
    "        return \"NoReference\"\n",
    "    elif sum(v) != 0: # exists\n",
    "        match = [['barcode1', 'barcode2', 'barcode3'][i] for (i, x) in enumerate(v) if x]\n",
    "        return \"\".join(match)\n",
    "    elif pd.isnull(x['barcode1']): # not exists\n",
    "        return 'NotInManifest'\n",
    "    else:\n",
    "        return 'Unmatch'\n",
    "def giveStatus2(x):\n",
    "    v = x[['barcode1', 'barcode2', 'barcode3']].isin([x['Second Shipment Barcodes']])\n",
    "    if pd.isnull(x['Second Shipment Barcodes']):\n",
    "        return \"NoReference\"\n",
    "    elif sum(v) != 0:\n",
    "        match = [['barcode1', 'barcode2', 'barcode3'][i] for (i, x) in enumerate(v) if x]\n",
    "        return \"\".join(match)\n",
    "    elif pd.isnull(x['barcode1']): # not exists\n",
    "        return 'NotInManifest'\n",
    "    else:\n",
    "        return 'Unmatch'\n",
    "Match['Match_1st'] = Match.apply(giveStatus1, axis=1)\n",
    "Match['Match_2nd'] = Match.apply(giveStatus2, axis=1)\n",
    "def giveStatusReport(x):\n",
    "    if x['Match_1st'] == 'NotInManifest':\n",
    "        return 'NotInManifest'\n",
    "    elif sum(x[['Match_1st', 'Match_2nd']] == 'NoReference') ==2:\n",
    "        if pd.notna(x['barcode1']):\n",
    "            return 'OnlyInManifest'\n",
    "        elif sum(pd.isnull(x[['1st Shipment Barcodes', 'Second Shipment Barcodes']]))<2:\n",
    "            return 'NotInManifest'\n",
    "        else:\n",
    "            return 'NoBarcode'\n",
    "    elif x['Match_1st'] == 'Unmatch':\n",
    "        if x['Match_2nd'] == 'NoReference':\n",
    "            return 'Unmatch'\n",
    "        else:\n",
    "            return '1stUnmatchBut2ndMatch'\n",
    "    elif x['Match_2nd'] == 'Unmatch':\n",
    "        if x['Match_1st'] == 'NoReference':\n",
    "            return 'Unmatch'\n",
    "        else:\n",
    "            return '1stMatchBut2ndUnmatch'\n",
    "    else:\n",
    "        return 'Match'\n",
    "Match['Report']=Match.apply(giveStatusReport, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda/envs/py3.5/lib/python3.5/site-packages/pandas/core/reshape/merge.py:765: RuntimeWarning: unorderable types: int() < str(), sort order is undefined for incomparable objects\n",
      "  sort=self.sort)\n"
     ]
    }
   ],
   "source": [
    "# Join with Fam file\n",
    "df=pd.read_table('/data/LNG/PPMI_WGS/july_2018/PPMI_july2018.fam', header=None, \n",
    "                 sep=' ',\n",
    "                 names = ['FID', 'IID','FAT', 'MAT','SEX', 'PHENO'])\n",
    "ID_genotyped = [y for x,y in df.iloc[:,0].str.split('SI')]\n",
    "ID_genotyped =list(map(int, ID_genotyped))\n",
    "df.index = ID_genotyped\n",
    "df.index = df.index.astype('object')\n",
    "genotyped = df.drop(['FID', 'FAT', 'MAT','SEX', 'PHENO'], 1)\n",
    "Match2 = Match.join(genotyped, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give Reporting IDs for those in the genpotyped\n",
    "def giveReportBCD(x):\n",
    "    if pd.notnull(x['IID']):\n",
    "        if x['Match_1st'] in ['barcode1', 'barcode2', 'barcode3']:\n",
    "            BCD = x['Match_1st']\n",
    "            ans = x[BCD]\n",
    "        elif x['Match_2nd'] in ['barcode1', 'barcode2', 'barcode3']:\n",
    "            BCD = x['Match_2nd']\n",
    "            ans = x[BCD]\n",
    "        else:\n",
    "            ans = np.nan\n",
    "    else:\n",
    "        ans = np.nan\n",
    "    return (ans)\n",
    "Match2['Reporting_ID'] = Match2.apply(giveReportBCD, axis = 1)\n",
    "Match2.to_csv(\"Matching.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Barcode_PPMI_NIA_AMPPD_ShipandSeq_Summary060118FINALC.xlsx\", \n",
    "                   sheet_name=\"PPMI smpls seq'd not on AMPPD\",\n",
    "                   header = None,\n",
    "                   dtype=object)\n",
    "t = df[0][pd.notna(df[0])]\n",
    "NOSENT = [i for i in t.tolist() if 'PPMI' in i]\n",
    "df_nosent = pd.DataFrame(data={'IID':NOSENT, 'Unshipped':'YES'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(Match2, df_nosent, on='IID', how='left')\n",
    "df.to_csv('/data/LNG/iwakih2/dataset/PPMI/WGS/Shipping/MatchingTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1820, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.5",
   "language": "python",
   "name": "py3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
